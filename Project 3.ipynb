{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6"
   },
   "source": [
    "# Using Reddit's API for Predicting Comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, we will practice two major skills. Collecting data via an API request and then building a binary predictor.\n",
    "\n",
    "As we discussed in week 2, and earlier today, there are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "For this article, your problem statement will be: _What characteristics of a post on Reddit contribute most to the overall interaction (as measured by number of comments)?_\n",
    "\n",
    "Your method for acquiring the data will be scraping the 'hot' threads as listed on the [Reddit homepage](https://www.reddit.com/). You'll acquire _AT LEAST FOUR_ pieces of information about each thread:\n",
    "1. The title of the thread\n",
    "2. The subreddit that the thread corresponds to\n",
    "3. The length of time it has been up on Reddit\n",
    "4. The number of comments on the thread\n",
    "\n",
    "Once you've got the data, you will build a classification model that, using Natural Language Processing and any other relevant features, predicts whether or not a given Reddit post will have above or below the _median_ number of comments.\n",
    "\n",
    "**BONUS PROBLEMS**\n",
    "1. If creating a logistic regression, GridSearch Ridge and Lasso for this model and report the best hyperparameter values.\n",
    "1. Scrape the actual text of the threads using Selenium (you'll learn about this in Webscraping II).\n",
    "2. Write the actual article that you're pitching and turn it into a blog post that you host on your personal website."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a948d79c-5527-4c0d-ab23-f5d43ce72056"
   },
   "source": [
    "### Scraping Thread Info from Reddit.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up a request (using requests) to the URL below. \n",
    "\n",
    "*NOTE*: Reddit will throw a [429 error](https://httpstatuses.com/429) when using the following code:\n",
    "```python\n",
    "res = requests.get(URL)\n",
    "```\n",
    "\n",
    "This is because Reddit has throttled python's default user agent. You'll need to set a custom `User-agent` to get your request to work.\n",
    "```python\n",
    "res = requests.get(URL, headers={'User-agent': 'YOUR NAME Bot 0.1'})\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer, TfidfVectorizer, TfidfTransformer\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import Imputer\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"http://www.reddit.com/hot.json\"\n",
    "res = requests.get(URL, headers = {'User-agent':'Raj Bot 0.1'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['kind', 'data'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['modhash', 'dist', 'children', 'after', 'before'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['data'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.status_code #200 is what you want! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n"
     ]
    }
   ],
   "source": [
    "print(len(data['data']['children']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "      <th>time fetched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Don_Thate</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>Removed the top of my desk for cleaning. Cat d...</td>\n",
       "      <td>46400</td>\n",
       "      <td>https://gfycat.com/ObviousShockingBronco</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-11 22:08:44.971936+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>50wpm</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>Tina Fey Says Liz Lemon And Leslie Knope Shoul...</td>\n",
       "      <td>21082</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/tina-fey-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-11 22:08:44.971936+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Mewiee</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>Just keep it steady</td>\n",
       "      <td>12994</td>\n",
       "      <td>https://v.redd.it/40wruaq1re311</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-11 22:08:44.971936+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>dim_ov</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>Cat saves his buddy from falling off a ledge</td>\n",
       "      <td>20810</td>\n",
       "      <td>https://gfycat.com/ThoroughExemplaryGreatdane</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-11 22:08:44.971936+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>dickfromaccounting</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140</td>\n",
       "      <td>Time-lapse of rain storm</td>\n",
       "      <td>15971</td>\n",
       "      <td>https://i.imgur.com/LUWQJCQ.gifv</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-11 22:08:44.971936+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc approved_by  archived              author  \\\n",
       "0            None        None     False           Don_Thate   \n",
       "1            None        None     False               50wpm   \n",
       "2            None        None     False              Mewiee   \n",
       "3            None        None     False              dim_ov   \n",
       "4            None        None     False  dickfromaccounting   \n",
       "\n",
       "  author_flair_background_color author_flair_css_class author_flair_richtext  \\\n",
       "0                          None                   None                    []   \n",
       "1                          None                   None                    []   \n",
       "2                          None                   None                    []   \n",
       "3                          None                   None                    []   \n",
       "4                          None                   None                    []   \n",
       "\n",
       "  author_flair_template_id author_flair_text author_flair_text_color  \\\n",
       "0                     None              None                    None   \n",
       "1                     None              None                    None   \n",
       "2                     None              None                    None   \n",
       "3                     None              None                    None   \n",
       "4                     None              None                    None   \n",
       "\n",
       "                 ...                thumbnail_width  \\\n",
       "0                ...                            140   \n",
       "1                ...                            140   \n",
       "2                ...                            140   \n",
       "3                ...                            140   \n",
       "4                ...                            140   \n",
       "\n",
       "                                               title    ups  \\\n",
       "0  Removed the top of my desk for cleaning. Cat d...  46400   \n",
       "1  Tina Fey Says Liz Lemon And Leslie Knope Shoul...  21082   \n",
       "2                                Just keep it steady  12994   \n",
       "3       Cat saves his buddy from falling off a ledge  20810   \n",
       "4                           Time-lapse of rain storm  15971   \n",
       "\n",
       "                                                 url  user_reports view_count  \\\n",
       "0           https://gfycat.com/ObviousShockingBronco            []       None   \n",
       "1  https://www.huffingtonpost.com/entry/tina-fey-...            []       None   \n",
       "2                    https://v.redd.it/40wruaq1re311            []       None   \n",
       "3      https://gfycat.com/ThoroughExemplaryGreatdane            []       None   \n",
       "4                   https://i.imgur.com/LUWQJCQ.gifv            []       None   \n",
       "\n",
       "   visited whitelist_status  wls                      time fetched  \n",
       "0    False          all_ads    6  2018-06-11 22:08:44.971936+00:00  \n",
       "1    False          all_ads    6  2018-06-11 22:08:44.971936+00:00  \n",
       "2    False          all_ads    6  2018-06-11 22:08:44.971936+00:00  \n",
       "3    False          all_ads    6  2018-06-11 22:08:44.971936+00:00  \n",
       "4    False          all_ads    6  2018-06-11 22:08:44.971936+00:00  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = [child['data'] for child in data['data']['children']]\n",
    "reddit = pd.DataFrame(reddit)\n",
    "time = pd.Timestamp.utcnow()\n",
    "reddit['time fetched'] = time\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 95)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['approved_at_utc', 'approved_by', 'archived', 'author',\n",
       "       'author_flair_background_color', 'author_flair_css_class',\n",
       "       'author_flair_richtext', 'author_flair_template_id',\n",
       "       'author_flair_text', 'author_flair_text_color', 'author_flair_type',\n",
       "       'banned_at_utc', 'banned_by', 'can_gild', 'can_mod_post', 'category',\n",
       "       'clicked', 'content_categories', 'contest_mode', 'created',\n",
       "       'created_utc', 'distinguished', 'domain', 'downs', 'edited', 'gilded',\n",
       "       'hidden', 'hide_score', 'id', 'is_crosspostable', 'is_original_content',\n",
       "       'is_reddit_media_domain', 'is_self', 'is_video', 'likes',\n",
       "       'link_flair_background_color', 'link_flair_css_class',\n",
       "       'link_flair_richtext', 'link_flair_template_id', 'link_flair_text',\n",
       "       'link_flair_text_color', 'link_flair_type', 'locked', 'media',\n",
       "       'media_embed', 'media_only', 'mod_note', 'mod_reason_by',\n",
       "       'mod_reason_title', 'mod_reports', 'name', 'no_follow', 'num_comments',\n",
       "       'num_crossposts', 'num_reports', 'over_18', 'parent_whitelist_status',\n",
       "       'permalink', 'pinned', 'post_categories', 'post_hint', 'preview',\n",
       "       'previous_visits', 'pwls', 'quarantine', 'removal_reason',\n",
       "       'report_reasons', 'rte_mode', 'saved', 'score', 'secure_media',\n",
       "       'secure_media_embed', 'selftext', 'selftext_html', 'send_replies',\n",
       "       'spoiler', 'stickied', 'subreddit', 'subreddit_id',\n",
       "       'subreddit_name_prefixed', 'subreddit_subscribers', 'subreddit_type',\n",
       "       'suggested_sort', 'thumbnail', 'thumbnail_height', 'thumbnail_width',\n",
       "       'title', 'ups', 'url', 'user_reports', 'view_count', 'visited',\n",
       "       'whitelist_status', 'wls', 'time fetched'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>approved_at_utc</th>\n",
       "      <th>approved_by</th>\n",
       "      <th>archived</th>\n",
       "      <th>author</th>\n",
       "      <th>author_cakeday</th>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <th>author_flair_text</th>\n",
       "      <th>...</th>\n",
       "      <th>thumbnail_width</th>\n",
       "      <th>time fetched</th>\n",
       "      <th>title</th>\n",
       "      <th>ups</th>\n",
       "      <th>url</th>\n",
       "      <th>user_reports</th>\n",
       "      <th>view_count</th>\n",
       "      <th>visited</th>\n",
       "      <th>whitelist_status</th>\n",
       "      <th>wls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Don_Thate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "      <td>Removed the top of my desk for cleaning. Cat d...</td>\n",
       "      <td>46400</td>\n",
       "      <td>https://gfycat.com/ObviousShockingBronco</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>50wpm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "      <td>Tina Fey Says Liz Lemon And Leslie Knope Shoul...</td>\n",
       "      <td>21082</td>\n",
       "      <td>https://www.huffingtonpost.com/entry/tina-fey-...</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>Mewiee</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "      <td>Just keep it steady</td>\n",
       "      <td>12994</td>\n",
       "      <td>https://v.redd.it/40wruaq1re311</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>dim_ov</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "      <td>Cat saves his buddy from falling off a ledge</td>\n",
       "      <td>20810</td>\n",
       "      <td>https://gfycat.com/ThoroughExemplaryGreatdane</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>dickfromaccounting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>140.0</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "      <td>Time-lapse of rain storm</td>\n",
       "      <td>15971</td>\n",
       "      <td>https://i.imgur.com/LUWQJCQ.gifv</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>all_ads</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  approved_at_utc approved_by  archived              author author_cakeday  \\\n",
       "0            None        None     False           Don_Thate            NaN   \n",
       "1            None        None     False               50wpm            NaN   \n",
       "2            None        None     False              Mewiee            NaN   \n",
       "3            None        None     False              dim_ov            NaN   \n",
       "4            None        None     False  dickfromaccounting            NaN   \n",
       "\n",
       "  author_flair_background_color author_flair_css_class author_flair_richtext  \\\n",
       "0                          None                   None                    []   \n",
       "1                          None                   None                    []   \n",
       "2                          None                   None                    []   \n",
       "3                          None                   None                    []   \n",
       "4                          None                   None                    []   \n",
       "\n",
       "  author_flair_template_id author_flair_text ...  thumbnail_width  \\\n",
       "0                     None              None ...            140.0   \n",
       "1                     None              None ...            140.0   \n",
       "2                     None              None ...            140.0   \n",
       "3                     None              None ...            140.0   \n",
       "4                     None              None ...            140.0   \n",
       "\n",
       "                       time fetched  \\\n",
       "0  2018-06-11 22:15:51.435208+00:00   \n",
       "1  2018-06-11 22:15:51.435208+00:00   \n",
       "2  2018-06-11 22:15:51.435208+00:00   \n",
       "3  2018-06-11 22:15:51.435208+00:00   \n",
       "4  2018-06-11 22:15:51.435208+00:00   \n",
       "\n",
       "                                               title    ups  \\\n",
       "0  Removed the top of my desk for cleaning. Cat d...  46400   \n",
       "1  Tina Fey Says Liz Lemon And Leslie Knope Shoul...  21082   \n",
       "2                                Just keep it steady  12994   \n",
       "3       Cat saves his buddy from falling off a ledge  20810   \n",
       "4                           Time-lapse of rain storm  15971   \n",
       "\n",
       "                                                 url  user_reports view_count  \\\n",
       "0           https://gfycat.com/ObviousShockingBronco            []       None   \n",
       "1  https://www.huffingtonpost.com/entry/tina-fey-...            []       None   \n",
       "2                    https://v.redd.it/40wruaq1re311            []       None   \n",
       "3      https://gfycat.com/ThoroughExemplaryGreatdane            []       None   \n",
       "4                   https://i.imgur.com/LUWQJCQ.gifv            []       None   \n",
       "\n",
       "   visited whitelist_status  wls  \n",
       "0    False          all_ads  6.0  \n",
       "1    False          all_ads  6.0  \n",
       "2    False          all_ads  6.0  \n",
       "3    False          all_ads  6.0  \n",
       "4    False          all_ads  6.0  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_post = data['data']['after']\n",
    "for i in range(0,200):\n",
    "    URL = \"http://www.reddit.com/hot.json?after=\" + next_post\n",
    "    res = requests.get(URL, headers = {'User-agent':'Raj Bot 0.1'})\n",
    "    post = res.json()\n",
    "    time_now = pd.Timestamp.utcnow()\n",
    "    next_post = post['data']['after']\n",
    "    post_df = [child['data'] for child in post['data']['children']]\n",
    "    post_df = pd.DataFrame(post_df)\n",
    "    reddit = pd.concat([reddit, post_df], ignore_index = True)\n",
    "    reddit['time fetched'] = time_now\n",
    "    sleep(1)\n",
    "reddit.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5275, 99)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>time fetched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Removed the top of my desk for cleaning. Cat d...</td>\n",
       "      <td>aww</td>\n",
       "      <td>486</td>\n",
       "      <td>1.528745e+09</td>\n",
       "      <td>8qc84c</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tina Fey Says Liz Lemon And Leslie Knope Shoul...</td>\n",
       "      <td>television</td>\n",
       "      <td>990</td>\n",
       "      <td>1.528742e+09</td>\n",
       "      <td>8qbqmn</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just keep it steady</td>\n",
       "      <td>combinedgifs</td>\n",
       "      <td>235</td>\n",
       "      <td>1.528739e+09</td>\n",
       "      <td>8qbbb3</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat saves his buddy from falling off a ledge</td>\n",
       "      <td>AnimalsBeingBros</td>\n",
       "      <td>211</td>\n",
       "      <td>1.528737e+09</td>\n",
       "      <td>8qb37o</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Time-lapse of rain storm</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>175</td>\n",
       "      <td>1.528737e+09</td>\n",
       "      <td>8qb0qq</td>\n",
       "      <td>2018-06-11 22:15:51.435208+00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         subreddit  \\\n",
       "0  Removed the top of my desk for cleaning. Cat d...               aww   \n",
       "1  Tina Fey Says Liz Lemon And Leslie Knope Shoul...        television   \n",
       "2                                Just keep it steady      combinedgifs   \n",
       "3       Cat saves his buddy from falling off a ledge  AnimalsBeingBros   \n",
       "4                           Time-lapse of rain storm          woahdude   \n",
       "\n",
       "   num_comments   created_utc      id                      time fetched  \n",
       "0           486  1.528745e+09  8qc84c  2018-06-11 22:15:51.435208+00:00  \n",
       "1           990  1.528742e+09  8qbqmn  2018-06-11 22:15:51.435208+00:00  \n",
       "2           235  1.528739e+09  8qbbb3  2018-06-11 22:15:51.435208+00:00  \n",
       "3           211  1.528737e+09  8qb37o  2018-06-11 22:15:51.435208+00:00  \n",
       "4           175  1.528737e+09  8qb0qq  2018-06-11 22:15:51.435208+00:00  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Look at 4 features: title, subreddit, num_comments, and created_utc# Look a \n",
    "reddit_new = reddit[['title', 'subreddit', 'num_comments', 'created_utc', 'id', 'time fetched']].copy(deep = True)\n",
    "reddit_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>time fetched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Removed the top of my desk for cleaning. Cat d...</td>\n",
       "      <td>aww</td>\n",
       "      <td>486</td>\n",
       "      <td>2018-06-11 19:27:23</td>\n",
       "      <td>8qc84c</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tina Fey Says Liz Lemon And Leslie Knope Shoul...</td>\n",
       "      <td>television</td>\n",
       "      <td>990</td>\n",
       "      <td>2018-06-11 18:31:18</td>\n",
       "      <td>8qbqmn</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just keep it steady</td>\n",
       "      <td>combinedgifs</td>\n",
       "      <td>235</td>\n",
       "      <td>2018-06-11 17:37:08</td>\n",
       "      <td>8qbbb3</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat saves his buddy from falling off a ledge</td>\n",
       "      <td>AnimalsBeingBros</td>\n",
       "      <td>211</td>\n",
       "      <td>2018-06-11 17:10:42</td>\n",
       "      <td>8qb37o</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Time-lapse of rain storm</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>175</td>\n",
       "      <td>2018-06-11 17:02:18</td>\n",
       "      <td>8qb0qq</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         subreddit  \\\n",
       "0  Removed the top of my desk for cleaning. Cat d...               aww   \n",
       "1  Tina Fey Says Liz Lemon And Leslie Knope Shoul...        television   \n",
       "2                                Just keep it steady      combinedgifs   \n",
       "3       Cat saves his buddy from falling off a ledge  AnimalsBeingBros   \n",
       "4                           Time-lapse of rain storm          woahdude   \n",
       "\n",
       "   num_comments         created_utc      id        time fetched  \n",
       "0           486 2018-06-11 19:27:23  8qc84c 2018-06-11 22:15:51  \n",
       "1           990 2018-06-11 18:31:18  8qbqmn 2018-06-11 22:15:51  \n",
       "2           235 2018-06-11 17:37:08  8qbbb3 2018-06-11 22:15:51  \n",
       "3           211 2018-06-11 17:10:42  8qb37o 2018-06-11 22:15:51  \n",
       "4           175 2018-06-11 17:02:18  8qb0qq 2018-06-11 22:15:51  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert created_utc to readable format\n",
    "reddit_new['created_utc'] = reddit_new['created_utc'].astype('datetime64[s]')\n",
    "reddit_new['time fetched'] = reddit_new['time fetched'].astype('datetime64[s]')\n",
    "reddit_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('reddit_new.pkl', 'wb') as f:\n",
    "    pickle.dump(reddit, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reddit_new.pkl', 'rb') as f:\n",
    "     reddit = pickle.load(f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5275, 6)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_new.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting more results\n",
    "\n",
    "By default, Reddit will give you the top 25 posts:\n",
    "\n",
    "```python\n",
    "print(len(data['data']['children']))\n",
    "```\n",
    "\n",
    "If you want more, you'll need to do two things:\n",
    "1. Get the name of the last post: `data['data']['after']`\n",
    "2. Use that name to hit the following url: `http://www.reddit.com/hot.json?after=THE_AFTER_FROM_STEP_1`\n",
    "3. Create a loop to repeat steps 1 and 2 until you have a sufficient number of posts. \n",
    "\n",
    "*NOTE*: Reddit will limit the number of requests per second you're allowed to make. When you create your loop, be sure to add the following after each iteration.\n",
    "\n",
    "```python\n",
    "time.sleep(3) # sleeps 3 seconds before continuing```\n",
    "\n",
    "This will throttle your loop and keep you within Reddit's guidelines. You'll need to import the `time` library for this to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (Optional) Collect more information\n",
    "\n",
    "While we only require you to collect four features, there may be other info that you can find on the results page that might be useful. Feel free to write more functions so that you have more interesting and useful data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "43e71edd-210e-42b1-9336-70a931f048af"
   },
   "source": [
    "### Save your results as a CSV\n",
    "You may do this regularly while scraping data as well, so that if your scraper stops of your computer crashes, you don't lose all your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "focus": false,
    "id": "783fd153-28ac-47ab-bfca-27e7c1de95b4"
   },
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "reddit_new.to_csv('project3scrape.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "04563b69-f7b6-466f-9d65-fc62c9ddee6a"
   },
   "source": [
    "## Predicting comments using Random Forests + Another Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "243e949e-2742-40af-872e-fec475fd306c"
   },
   "source": [
    "#### Load in the the data of scraped results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "focus": false,
    "id": "588f9845-6143-4bcc-bfd1-85d45b79303d"
   },
   "outputs": [],
   "source": [
    "## Reading in the code \n",
    "comment_predictor = pd.read_csv('project3scrape.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping first column since it is uncesssary \n",
    "comment_predictor.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5275, 6)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape to see \n",
    "comment_predictor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>time fetched</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Removed the top of my desk for cleaning. Cat d...</td>\n",
       "      <td>aww</td>\n",
       "      <td>486</td>\n",
       "      <td>2018-06-11 19:27:23</td>\n",
       "      <td>8qc84c</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tina Fey Says Liz Lemon And Leslie Knope Shoul...</td>\n",
       "      <td>television</td>\n",
       "      <td>990</td>\n",
       "      <td>2018-06-11 18:31:18</td>\n",
       "      <td>8qbqmn</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just keep it steady</td>\n",
       "      <td>combinedgifs</td>\n",
       "      <td>235</td>\n",
       "      <td>2018-06-11 17:37:08</td>\n",
       "      <td>8qbbb3</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat saves his buddy from falling off a ledge</td>\n",
       "      <td>AnimalsBeingBros</td>\n",
       "      <td>211</td>\n",
       "      <td>2018-06-11 17:10:42</td>\n",
       "      <td>8qb37o</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Time-lapse of rain storm</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>175</td>\n",
       "      <td>2018-06-11 17:02:18</td>\n",
       "      <td>8qb0qq</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For us ladies on budget</td>\n",
       "      <td>ShittyLifeProTips</td>\n",
       "      <td>368</td>\n",
       "      <td>2018-06-11 17:13:08</td>\n",
       "      <td>8qb3ze</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[THENEEDLEDROP] KIDS SEE GHOSTS Album Review</td>\n",
       "      <td>Kanye</td>\n",
       "      <td>702</td>\n",
       "      <td>2018-06-11 19:01:07</td>\n",
       "      <td>8qc009</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RIP net neutrality: Ajit Pai's 'fuck you' to t...</td>\n",
       "      <td>technology</td>\n",
       "      <td>2867</td>\n",
       "      <td>2018-06-11 15:54:30</td>\n",
       "      <td>8qammr</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10 Most Downvoted Reddit Comments [OC]</td>\n",
       "      <td>dataisbeautiful</td>\n",
       "      <td>368</td>\n",
       "      <td>2018-06-11 19:42:18</td>\n",
       "      <td>8qccrn</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Forbidden Ice Cream</td>\n",
       "      <td>forbiddensnacks</td>\n",
       "      <td>117</td>\n",
       "      <td>2018-06-11 17:00:23</td>\n",
       "      <td>8qb0bd</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>When Reddit’s down and work is slow</td>\n",
       "      <td>IASIP</td>\n",
       "      <td>87</td>\n",
       "      <td>2018-06-11 17:06:56</td>\n",
       "      <td>8qb22m</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>High school pitcher strikes out his childhood ...</td>\n",
       "      <td>gifs</td>\n",
       "      <td>610</td>\n",
       "      <td>2018-06-11 15:57:17</td>\n",
       "      <td>8qanfo</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>TIL when Ben and Jerry's started giving its mi...</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>219</td>\n",
       "      <td>2018-06-11 18:38:22</td>\n",
       "      <td>8qbsvq</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>a laser \"dot\" at 4km distance</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>336</td>\n",
       "      <td>2018-06-11 17:07:42</td>\n",
       "      <td>8qb2a4</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BeAr ViScOuSlY AtTaCkS dOg</td>\n",
       "      <td>PeopleFuckingDying</td>\n",
       "      <td>97</td>\n",
       "      <td>2018-06-11 19:09:46</td>\n",
       "      <td>8qc2rt</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>What do you think of role-play?</td>\n",
       "      <td>DunderMifflin</td>\n",
       "      <td>278</td>\n",
       "      <td>2018-06-11 15:09:01</td>\n",
       "      <td>8qa9de</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Skate 4</td>\n",
       "      <td>gaming</td>\n",
       "      <td>104</td>\n",
       "      <td>2018-06-11 17:33:30</td>\n",
       "      <td>8qba9k</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>I’m this unpopular</td>\n",
       "      <td>softwaregore</td>\n",
       "      <td>64</td>\n",
       "      <td>2018-06-11 17:48:12</td>\n",
       "      <td>8qbely</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>My supervisor went to see Deadpool 2 over the ...</td>\n",
       "      <td>funny</td>\n",
       "      <td>237</td>\n",
       "      <td>2018-06-11 15:16:05</td>\n",
       "      <td>8qabde</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Freaking Brutal</td>\n",
       "      <td>pics</td>\n",
       "      <td>2149</td>\n",
       "      <td>2018-06-11 15:13:31</td>\n",
       "      <td>8qaaoq</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>meirl</td>\n",
       "      <td>meirl</td>\n",
       "      <td>80</td>\n",
       "      <td>2018-06-11 15:23:20</td>\n",
       "      <td>8qadfu</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Norway PM Says the U.S. Is Losing Global Sway</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>1582</td>\n",
       "      <td>2018-06-11 15:30:27</td>\n",
       "      <td>8qafh6</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BestBuy has YouTube/Netflix/Hulu listed on Swi...</td>\n",
       "      <td>NintendoSwitch</td>\n",
       "      <td>324</td>\n",
       "      <td>2018-06-11 19:38:01</td>\n",
       "      <td>8qcbe2</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>When your ex looking like a Whor'dourves</td>\n",
       "      <td>BlackPeopleTwitter</td>\n",
       "      <td>245</td>\n",
       "      <td>2018-06-11 13:50:01</td>\n",
       "      <td>8q9o5m</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>On the roof.</td>\n",
       "      <td>creepy</td>\n",
       "      <td>189</td>\n",
       "      <td>2018-06-11 15:45:56</td>\n",
       "      <td>8qak4d</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Pit bull saves family from house fire, pulls 7...</td>\n",
       "      <td>news</td>\n",
       "      <td>2667</td>\n",
       "      <td>2018-06-11 14:25:30</td>\n",
       "      <td>8q9xbx</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Almost slept through this amazing sunrise at M...</td>\n",
       "      <td>EarthPorn</td>\n",
       "      <td>168</td>\n",
       "      <td>2018-06-11 13:41:47</td>\n",
       "      <td>8q9m30</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>You can feel the joke going over their head</td>\n",
       "      <td>woooosh</td>\n",
       "      <td>169</td>\n",
       "      <td>2018-06-11 15:31:27</td>\n",
       "      <td>8qafs6</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TIFU by accidentally buying tickets to the Red...</td>\n",
       "      <td>tifu</td>\n",
       "      <td>944</td>\n",
       "      <td>2018-06-11 14:24:49</td>\n",
       "      <td>8q9x56</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Be Kind &amp;amp; Rewind</td>\n",
       "      <td>WhitePeopleTwitter</td>\n",
       "      <td>42</td>\n",
       "      <td>2018-06-11 17:56:05</td>\n",
       "      <td>8qbgie</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5245</th>\n",
       "      <td>New faction confirmed!</td>\n",
       "      <td>forhonor</td>\n",
       "      <td>68</td>\n",
       "      <td>2018-06-11 20:26:08</td>\n",
       "      <td>8qcpzi</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5246</th>\n",
       "      <td>Trump administration moves to block victims of...</td>\n",
       "      <td>worldnews</td>\n",
       "      <td>17</td>\n",
       "      <td>2018-06-11 19:44:56</td>\n",
       "      <td>8qcdlh</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5247</th>\n",
       "      <td>Cat Noir</td>\n",
       "      <td>tumblr</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-11 15:17:00</td>\n",
       "      <td>8qabmj</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5248</th>\n",
       "      <td>Doesn't take much to look dapper!</td>\n",
       "      <td>aww</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-06-11 09:33:20</td>\n",
       "      <td>8q87h8</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>Overeem post-fight message</td>\n",
       "      <td>MMA</td>\n",
       "      <td>114</td>\n",
       "      <td>2018-06-11 13:50:44</td>\n",
       "      <td>8q9obz</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5250</th>\n",
       "      <td>Ugh, Karen. Come on!</td>\n",
       "      <td>WhitePeopleTwitter</td>\n",
       "      <td>2</td>\n",
       "      <td>2018-06-11 13:58:17</td>\n",
       "      <td>8q9q5m</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5251</th>\n",
       "      <td>Smol Natsuki by yoncco</td>\n",
       "      <td>DDLC</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-06-11 19:42:38</td>\n",
       "      <td>8qccvc</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5252</th>\n",
       "      <td>Mexican drug cartel leader \"La Barbie\" gets ne...</td>\n",
       "      <td>news</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-06-11 17:07:59</td>\n",
       "      <td>8qb2cr</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5253</th>\n",
       "      <td>A button I picked up at DC Pride</td>\n",
       "      <td>PoliticalHumor</td>\n",
       "      <td>18</td>\n",
       "      <td>2018-06-11 17:16:20</td>\n",
       "      <td>8qb4zw</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5254</th>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>2meirl4meirl</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-06-11 17:30:26</td>\n",
       "      <td>8qb99y</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5255</th>\n",
       "      <td>TIL an astronomer was frightened by the jumpin...</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>152</td>\n",
       "      <td>2018-06-10 22:48:19</td>\n",
       "      <td>8q4ljw</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5256</th>\n",
       "      <td>My roommate left this onion in our fridge when...</td>\n",
       "      <td>mildlyinteresting</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-06-11 19:38:38</td>\n",
       "      <td>8qcbm9</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>Sign on the last day of school. Infinity no ta...</td>\n",
       "      <td>funny</td>\n",
       "      <td>16</td>\n",
       "      <td>2018-06-11 14:55:45</td>\n",
       "      <td>8qa5la</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5258</th>\n",
       "      <td>Comments in Elder Scrolls 6 threads be like</td>\n",
       "      <td>ElderScrolls</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-11 17:11:45</td>\n",
       "      <td>8qb3ko</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5259</th>\n",
       "      <td>Yooka-Laylee confirmed to receive physical edi...</td>\n",
       "      <td>NintendoSwitch</td>\n",
       "      <td>20</td>\n",
       "      <td>2018-06-11 19:30:58</td>\n",
       "      <td>8qc96h</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5260</th>\n",
       "      <td>Exactly</td>\n",
       "      <td>PewdiepieSubmissions</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-11 15:16:05</td>\n",
       "      <td>8qabdc</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5261</th>\n",
       "      <td>Giga (courtesy of BIS)</td>\n",
       "      <td>jurassicworldevo</td>\n",
       "      <td>48</td>\n",
       "      <td>2018-06-11 12:15:54</td>\n",
       "      <td>8q92a0</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5262</th>\n",
       "      <td>Anna Kendrick from Pitch Perfect knows who her...</td>\n",
       "      <td>rupaulsdragrace</td>\n",
       "      <td>36</td>\n",
       "      <td>2018-06-11 12:40:11</td>\n",
       "      <td>8q97n7</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5263</th>\n",
       "      <td>Found this on the Cyberpunk 2077 trailer. A ga...</td>\n",
       "      <td>CringeAnarchy</td>\n",
       "      <td>11</td>\n",
       "      <td>2018-06-11 17:30:09</td>\n",
       "      <td>8qb970</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5264</th>\n",
       "      <td>A muslim dies and goes to heaven...</td>\n",
       "      <td>Jokes</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-06-11 19:27:47</td>\n",
       "      <td>8qc88f</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5265</th>\n",
       "      <td>🍉GOD BLESS THE MELON 🍉</td>\n",
       "      <td>Kanye</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-06-11 19:11:52</td>\n",
       "      <td>8qc3gy</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5266</th>\n",
       "      <td>That's right</td>\n",
       "      <td>greentext</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-11 20:19:27</td>\n",
       "      <td>8qco1k</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5267</th>\n",
       "      <td>Almost slept through this amazing sunrise in M...</td>\n",
       "      <td>pics</td>\n",
       "      <td>10</td>\n",
       "      <td>2018-06-11 20:03:25</td>\n",
       "      <td>8qcj6z</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5268</th>\n",
       "      <td>LIKE IF PETA BIG GAY</td>\n",
       "      <td>DeepFriedMemes</td>\n",
       "      <td>7</td>\n",
       "      <td>2018-06-11 14:22:18</td>\n",
       "      <td>8q9wh5</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5269</th>\n",
       "      <td>When you've tried everything</td>\n",
       "      <td>PrequelMemes</td>\n",
       "      <td>25</td>\n",
       "      <td>2018-06-11 12:17:00</td>\n",
       "      <td>8q92iw</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5270</th>\n",
       "      <td>I've created a monster</td>\n",
       "      <td>FireEmblemHeroes</td>\n",
       "      <td>19</td>\n",
       "      <td>2018-06-11 18:03:36</td>\n",
       "      <td>8qbif4</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5271</th>\n",
       "      <td>furry_irl</td>\n",
       "      <td>furry_irl</td>\n",
       "      <td>15</td>\n",
       "      <td>2018-06-11 19:08:45</td>\n",
       "      <td>8qc2g1</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5272</th>\n",
       "      <td>Hold it right there buddy. Give me $60 to preo...</td>\n",
       "      <td>Gamingcirclejerk</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-06-11 15:42:47</td>\n",
       "      <td>8qaj6a</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5273</th>\n",
       "      <td>Mike Ybarra on Twitter - 6 Month Game Pass bac...</td>\n",
       "      <td>xboxone</td>\n",
       "      <td>26</td>\n",
       "      <td>2018-06-11 15:35:05</td>\n",
       "      <td>8qagu5</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5274</th>\n",
       "      <td>Slow Jerk</td>\n",
       "      <td>videos</td>\n",
       "      <td>4</td>\n",
       "      <td>2018-06-11 20:07:10</td>\n",
       "      <td>8qckaa</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5275 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title             subreddit  \\\n",
       "0     Removed the top of my desk for cleaning. Cat d...                   aww   \n",
       "1     Tina Fey Says Liz Lemon And Leslie Knope Shoul...            television   \n",
       "2                                   Just keep it steady          combinedgifs   \n",
       "3          Cat saves his buddy from falling off a ledge      AnimalsBeingBros   \n",
       "4                              Time-lapse of rain storm              woahdude   \n",
       "5                               For us ladies on budget     ShittyLifeProTips   \n",
       "6          [THENEEDLEDROP] KIDS SEE GHOSTS Album Review                 Kanye   \n",
       "7     RIP net neutrality: Ajit Pai's 'fuck you' to t...            technology   \n",
       "8                10 Most Downvoted Reddit Comments [OC]       dataisbeautiful   \n",
       "9                                   Forbidden Ice Cream       forbiddensnacks   \n",
       "10                  When Reddit’s down and work is slow                 IASIP   \n",
       "11    High school pitcher strikes out his childhood ...                  gifs   \n",
       "12    TIL when Ben and Jerry's started giving its mi...         todayilearned   \n",
       "13                        a laser \"dot\" at 4km distance     mildlyinteresting   \n",
       "14                           BeAr ViScOuSlY AtTaCkS dOg    PeopleFuckingDying   \n",
       "15                      What do you think of role-play?         DunderMifflin   \n",
       "16                                              Skate 4                gaming   \n",
       "17                                   I’m this unpopular          softwaregore   \n",
       "18    My supervisor went to see Deadpool 2 over the ...                 funny   \n",
       "19                                      Freaking Brutal                  pics   \n",
       "20                                                meirl                 meirl   \n",
       "21        Norway PM Says the U.S. Is Losing Global Sway             worldnews   \n",
       "22    BestBuy has YouTube/Netflix/Hulu listed on Swi...        NintendoSwitch   \n",
       "23             When your ex looking like a Whor'dourves    BlackPeopleTwitter   \n",
       "24                                         On the roof.                creepy   \n",
       "25    Pit bull saves family from house fire, pulls 7...                  news   \n",
       "26    Almost slept through this amazing sunrise at M...             EarthPorn   \n",
       "27          You can feel the joke going over their head               woooosh   \n",
       "28    TIFU by accidentally buying tickets to the Red...                  tifu   \n",
       "29                                 Be Kind &amp; Rewind    WhitePeopleTwitter   \n",
       "...                                                 ...                   ...   \n",
       "5245                             New faction confirmed!              forhonor   \n",
       "5246  Trump administration moves to block victims of...             worldnews   \n",
       "5247                                           Cat Noir                tumblr   \n",
       "5248                  Doesn't take much to look dapper!                   aww   \n",
       "5249                         Overeem post-fight message                   MMA   \n",
       "5250                               Ugh, Karen. Come on!    WhitePeopleTwitter   \n",
       "5251                             Smol Natsuki by yoncco                  DDLC   \n",
       "5252  Mexican drug cartel leader \"La Barbie\" gets ne...                  news   \n",
       "5253                   A button I picked up at DC Pride        PoliticalHumor   \n",
       "5254                                       2meirl4meirl          2meirl4meirl   \n",
       "5255  TIL an astronomer was frightened by the jumpin...         todayilearned   \n",
       "5256  My roommate left this onion in our fridge when...     mildlyinteresting   \n",
       "5257  Sign on the last day of school. Infinity no ta...                 funny   \n",
       "5258        Comments in Elder Scrolls 6 threads be like          ElderScrolls   \n",
       "5259  Yooka-Laylee confirmed to receive physical edi...        NintendoSwitch   \n",
       "5260                                            Exactly  PewdiepieSubmissions   \n",
       "5261                             Giga (courtesy of BIS)      jurassicworldevo   \n",
       "5262  Anna Kendrick from Pitch Perfect knows who her...       rupaulsdragrace   \n",
       "5263  Found this on the Cyberpunk 2077 trailer. A ga...         CringeAnarchy   \n",
       "5264                A muslim dies and goes to heaven...                 Jokes   \n",
       "5265                             🍉GOD BLESS THE MELON 🍉                 Kanye   \n",
       "5266                                       That's right             greentext   \n",
       "5267  Almost slept through this amazing sunrise in M...                  pics   \n",
       "5268                               LIKE IF PETA BIG GAY        DeepFriedMemes   \n",
       "5269                       When you've tried everything          PrequelMemes   \n",
       "5270                             I've created a monster      FireEmblemHeroes   \n",
       "5271                                          furry_irl             furry_irl   \n",
       "5272  Hold it right there buddy. Give me $60 to preo...      Gamingcirclejerk   \n",
       "5273  Mike Ybarra on Twitter - 6 Month Game Pass bac...               xboxone   \n",
       "5274                                          Slow Jerk                videos   \n",
       "\n",
       "      num_comments          created_utc      id         time fetched  \n",
       "0              486  2018-06-11 19:27:23  8qc84c  2018-06-11 22:15:51  \n",
       "1              990  2018-06-11 18:31:18  8qbqmn  2018-06-11 22:15:51  \n",
       "2              235  2018-06-11 17:37:08  8qbbb3  2018-06-11 22:15:51  \n",
       "3              211  2018-06-11 17:10:42  8qb37o  2018-06-11 22:15:51  \n",
       "4              175  2018-06-11 17:02:18  8qb0qq  2018-06-11 22:15:51  \n",
       "5              368  2018-06-11 17:13:08  8qb3ze  2018-06-11 22:15:51  \n",
       "6              702  2018-06-11 19:01:07  8qc009  2018-06-11 22:15:51  \n",
       "7             2867  2018-06-11 15:54:30  8qammr  2018-06-11 22:15:51  \n",
       "8              368  2018-06-11 19:42:18  8qccrn  2018-06-11 22:15:51  \n",
       "9              117  2018-06-11 17:00:23  8qb0bd  2018-06-11 22:15:51  \n",
       "10              87  2018-06-11 17:06:56  8qb22m  2018-06-11 22:15:51  \n",
       "11             610  2018-06-11 15:57:17  8qanfo  2018-06-11 22:15:51  \n",
       "12             219  2018-06-11 18:38:22  8qbsvq  2018-06-11 22:15:51  \n",
       "13             336  2018-06-11 17:07:42  8qb2a4  2018-06-11 22:15:51  \n",
       "14              97  2018-06-11 19:09:46  8qc2rt  2018-06-11 22:15:51  \n",
       "15             278  2018-06-11 15:09:01  8qa9de  2018-06-11 22:15:51  \n",
       "16             104  2018-06-11 17:33:30  8qba9k  2018-06-11 22:15:51  \n",
       "17              64  2018-06-11 17:48:12  8qbely  2018-06-11 22:15:51  \n",
       "18             237  2018-06-11 15:16:05  8qabde  2018-06-11 22:15:51  \n",
       "19            2149  2018-06-11 15:13:31  8qaaoq  2018-06-11 22:15:51  \n",
       "20              80  2018-06-11 15:23:20  8qadfu  2018-06-11 22:15:51  \n",
       "21            1582  2018-06-11 15:30:27  8qafh6  2018-06-11 22:15:51  \n",
       "22             324  2018-06-11 19:38:01  8qcbe2  2018-06-11 22:15:51  \n",
       "23             245  2018-06-11 13:50:01  8q9o5m  2018-06-11 22:15:51  \n",
       "24             189  2018-06-11 15:45:56  8qak4d  2018-06-11 22:15:51  \n",
       "25            2667  2018-06-11 14:25:30  8q9xbx  2018-06-11 22:15:51  \n",
       "26             168  2018-06-11 13:41:47  8q9m30  2018-06-11 22:15:51  \n",
       "27             169  2018-06-11 15:31:27  8qafs6  2018-06-11 22:15:51  \n",
       "28             944  2018-06-11 14:24:49  8q9x56  2018-06-11 22:15:51  \n",
       "29              42  2018-06-11 17:56:05  8qbgie  2018-06-11 22:15:51  \n",
       "...            ...                  ...     ...                  ...  \n",
       "5245            68  2018-06-11 20:26:08  8qcpzi  2018-06-11 22:15:51  \n",
       "5246            17  2018-06-11 19:44:56  8qcdlh  2018-06-11 22:15:51  \n",
       "5247             4  2018-06-11 15:17:00  8qabmj  2018-06-11 22:15:51  \n",
       "5248            29  2018-06-11 09:33:20  8q87h8  2018-06-11 22:15:51  \n",
       "5249           114  2018-06-11 13:50:44  8q9obz  2018-06-11 22:15:51  \n",
       "5250             2  2018-06-11 13:58:17  8q9q5m  2018-06-11 22:15:51  \n",
       "5251            12  2018-06-11 19:42:38  8qccvc  2018-06-11 22:15:51  \n",
       "5252            29  2018-06-11 17:07:59  8qb2cr  2018-06-11 22:15:51  \n",
       "5253            18  2018-06-11 17:16:20  8qb4zw  2018-06-11 22:15:51  \n",
       "5254             0  2018-06-11 17:30:26  8qb99y  2018-06-11 22:15:51  \n",
       "5255           152  2018-06-10 22:48:19  8q4ljw  2018-06-11 22:15:51  \n",
       "5256            11  2018-06-11 19:38:38  8qcbm9  2018-06-11 22:15:51  \n",
       "5257            16  2018-06-11 14:55:45  8qa5la  2018-06-11 22:15:51  \n",
       "5258             3  2018-06-11 17:11:45  8qb3ko  2018-06-11 22:15:51  \n",
       "5259            20  2018-06-11 19:30:58  8qc96h  2018-06-11 22:15:51  \n",
       "5260             6  2018-06-11 15:16:05  8qabdc  2018-06-11 22:15:51  \n",
       "5261            48  2018-06-11 12:15:54  8q92a0  2018-06-11 22:15:51  \n",
       "5262            36  2018-06-11 12:40:11  8q97n7  2018-06-11 22:15:51  \n",
       "5263            11  2018-06-11 17:30:09  8qb970  2018-06-11 22:15:51  \n",
       "5264            10  2018-06-11 19:27:47  8qc88f  2018-06-11 22:15:51  \n",
       "5265             6  2018-06-11 19:11:52  8qc3gy  2018-06-11 22:15:51  \n",
       "5266             3  2018-06-11 20:19:27  8qco1k  2018-06-11 22:15:51  \n",
       "5267            10  2018-06-11 20:03:25  8qcj6z  2018-06-11 22:15:51  \n",
       "5268             7  2018-06-11 14:22:18  8q9wh5  2018-06-11 22:15:51  \n",
       "5269            25  2018-06-11 12:17:00  8q92iw  2018-06-11 22:15:51  \n",
       "5270            19  2018-06-11 18:03:36  8qbif4  2018-06-11 22:15:51  \n",
       "5271            15  2018-06-11 19:08:45  8qc2g1  2018-06-11 22:15:51  \n",
       "5272             3  2018-06-11 15:42:47  8qaj6a  2018-06-11 22:15:51  \n",
       "5273            26  2018-06-11 15:35:05  8qagu5  2018-06-11 22:15:51  \n",
       "5274             4  2018-06-11 20:07:10  8qckaa  2018-06-11 22:15:51  \n",
       "\n",
       "[5275 rows x 6 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking my data frame\n",
    "comment_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "c7631f51-07f2-4c79-a093-3e9bc7849a48"
   },
   "source": [
    "#### We want to predict a binary variable - whether the number of comments was low or high. Compute the median number of comments and create a new binary variable that is true when the number of comments is high (above the median)\n",
    "\n",
    "We could also perform Linear Regression (or any regression) to predict the number of comments here. Instead, we are going to convert this into a _binary_ classification problem, by predicting two classes, HIGH vs LOW number of comments.\n",
    "\n",
    "While performing regression may be better, performing classification may help remove some of the noise of the extremely popular threads. We don't _have_ to choose the `median` as the splitting point - we could also split on the 75th percentile or any other reasonable breaking point.\n",
    "\n",
    "In fact, the ideal scenario may be to predict many levels of comment numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Find medium of the number of comments for each feature \n",
    "\n",
    "med_comment = comment_predictor['num_comments'].median()\n",
    "med_comment\n",
    "#It's 23 comments!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "focus": false,
    "id": "c20d2498-151c-44c3-a453-3a333c79a0ac",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>time fetched</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Removed the top of my desk for cleaning. Cat d...</td>\n",
       "      <td>aww</td>\n",
       "      <td>486</td>\n",
       "      <td>2018-06-11 19:27:23</td>\n",
       "      <td>8qc84c</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tina Fey Says Liz Lemon And Leslie Knope Shoul...</td>\n",
       "      <td>television</td>\n",
       "      <td>990</td>\n",
       "      <td>2018-06-11 18:31:18</td>\n",
       "      <td>8qbqmn</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just keep it steady</td>\n",
       "      <td>combinedgifs</td>\n",
       "      <td>235</td>\n",
       "      <td>2018-06-11 17:37:08</td>\n",
       "      <td>8qbbb3</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat saves his buddy from falling off a ledge</td>\n",
       "      <td>AnimalsBeingBros</td>\n",
       "      <td>211</td>\n",
       "      <td>2018-06-11 17:10:42</td>\n",
       "      <td>8qb37o</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Time-lapse of rain storm</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>175</td>\n",
       "      <td>2018-06-11 17:02:18</td>\n",
       "      <td>8qb0qq</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         subreddit  \\\n",
       "0  Removed the top of my desk for cleaning. Cat d...               aww   \n",
       "1  Tina Fey Says Liz Lemon And Leslie Knope Shoul...        television   \n",
       "2                                Just keep it steady      combinedgifs   \n",
       "3       Cat saves his buddy from falling off a ledge  AnimalsBeingBros   \n",
       "4                           Time-lapse of rain storm          woahdude   \n",
       "\n",
       "   num_comments          created_utc      id         time fetched Class  \n",
       "0           486  2018-06-11 19:27:23  8qc84c  2018-06-11 22:15:51  HIGH  \n",
       "1           990  2018-06-11 18:31:18  8qbqmn  2018-06-11 22:15:51  HIGH  \n",
       "2           235  2018-06-11 17:37:08  8qbbb3  2018-06-11 22:15:51  HIGH  \n",
       "3           211  2018-06-11 17:10:42  8qb37o  2018-06-11 22:15:51  HIGH  \n",
       "4           175  2018-06-11 17:02:18  8qb0qq  2018-06-11 22:15:51  HIGH  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Creating binary High vs Low column for the comments\n",
    "comment_predictor['Class'] = comment_predictor.apply(lambda x: 'HIGH' if x['num_comments'] > med_comment else 'LOW', axis=1)\n",
    "\n",
    "comment_predictor.head()\n",
    "\n",
    "#Only one of my features is under the median, all others are above\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "a7afb2c0-d41e-4779-8216-91cd8dd4473f"
   },
   "source": [
    "#### Thought experiment: What is the baseline accuracy for this model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.38862559241706"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Baseline accuracy is 50% \n",
    "\n",
    "comment_predictor.Class.value_counts()[0] / len(comment_predictor) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since baseline accuracy is the majority class, my baseline  accuracy is 52%, the LOW class comments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4fb29de2-5b98-474c-a4ad-5170b72b9aea"
   },
   "source": [
    "#### Create a Random Forest model to predict High/Low number of comments using Sklearn. Start by ONLY using the subreddit as a feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# https://towardsdatascience.com/running-random-forests-inspect-the-feature-importances-with-this-code-2b00dd72b92e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "focus": false,
    "id": "ddbc6159-6854-4ca7-857f-bfecdaf6d9c2"
   },
   "outputs": [],
   "source": [
    "# Building random forest model to predict High/Low number of comments using only subreddit feature\n",
    "# Definte X,y\n",
    "X = comment_predictor['subreddit']\n",
    "y = comment_predictor['Class'].apply(lambda x: 1 if x == 'HIGH' else 0)\n",
    "\n",
    "X = pd.get_dummies(X, drop_first = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Train / Test Split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score on Test data: 0.6626658243840808\n",
      "Score on Train data : 0.7955037919826652\n"
     ]
    }
   ],
   "source": [
    "# RFM\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print('Score on Test data: {}'.format(rf.score(X_test, y_test)))\n",
    "print('Score on Train data : {}'.format(rf.score(X_train, y_train)))\n",
    "\n",
    "#How can I meaningfully interpret these kind of results? If it was lower, I would say it's overfitting. Is there something to be said about bias and variance in this case by looking all the results? What can I do to make this classification meaningful, such as re-selecting training and test sets or just using cross-validation on all data?\n",
    "\n",
    "#Model is overfitting since the test data is lower than the train data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6375947995666306\n",
      "{'min_samples_split': 4, 'n_estimators': 50}\n",
      "0.6797220467466835\n"
     ]
    }
   ],
   "source": [
    " # Gridsearch Model to get a better test model score \n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {'min_samples_split' : range(2,10),\n",
    "             'n_estimators' : [50, 50 , 150]}\n",
    "\n",
    "gs = GridSearchCV(rf, param_grid=rf_params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model is doing better now with a train score of 52% and a test score of 50%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "0ef04f32-419c-4bf2-baf7-48201f03df89"
   },
   "source": [
    "#### Create a few new variables in your dataframe to represent interesting features of a thread title.\n",
    "- For example, create a feature that represents whether 'cat' is in the title or whether 'funny' is in the title. \n",
    "- Then build a new Random Forest with these features. Do they add any value?\n",
    "- After creating these variables, use count-vectorizer to create features based on the words in the thread titles.\n",
    "- Build a new random forest model with subreddit and these new features included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating new features to check if cat/funny in title \n",
    "\n",
    "X = comment_predictor[['title', 'subreddit']].copy(deep=True)\n",
    "y = comment_predictor['Class'].apply(lambda x: 1 if x == 'HIGH' else 0)\n",
    "\n",
    "X['Cat'] = X['title'].map(lambda x: 1 if 'cat' in x else 0)\n",
    "X['Funny'] = X['title'].map(lambda x: 1 if 'funny' in x else 0)\n",
    "X = pd.get_dummies(X, drop_first=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cat</th>\n",
       "      <th>Funny</th>\n",
       "      <th>title_\"Alexa, start a discussion about marketing budgets in video games.\" \"Did you say slapfight?\"</th>\n",
       "      <th>title_\"Art\" by Salvador Larroca..</th>\n",
       "      <th>title_\"Attorney Denies Robert De Niro Was Client of Prostitution Ring With Underage Girls; Police Interrogated Star for Nine Hours – True PunditTrue Pundit\" A *Nine* hour interview and his very high priced Lawyers would've been pushing for it to be brief to prevent inadvertent selfincriminating. Right?</th>\n",
       "      <th>title_\"Automata\" DUST Trailer - Episode 1 premieres on June 12th</th>\n",
       "      <th>title_\"Balancing Act\", Digital, 720x720, Collab with Broken Isnt Bad</th>\n",
       "      <th>title_\"Bandit\" in cinemas soon</th>\n",
       "      <th>title_\"Canada burned down the White House during the war of 1812\" - Trump</th>\n",
       "      <th>title_\"Coffee, tea, or... me?\"</th>\n",
       "      <th>...</th>\n",
       "      <th>subreddit_xxfitness</th>\n",
       "      <th>subreddit_yakuzagames</th>\n",
       "      <th>subreddit_yesyesyesno</th>\n",
       "      <th>subreddit_yesyesyesyesno</th>\n",
       "      <th>subreddit_youdontsurf</th>\n",
       "      <th>subreddit_youseeingthisshit</th>\n",
       "      <th>subreddit_youtube</th>\n",
       "      <th>subreddit_youtubehaiku</th>\n",
       "      <th>subreddit_zelda</th>\n",
       "      <th>subreddit_zerocarb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6671 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Cat  Funny  \\\n",
       "0    0      0   \n",
       "1    0      0   \n",
       "2    0      0   \n",
       "3    0      0   \n",
       "4    0      0   \n",
       "\n",
       "   title_\"Alexa, start a discussion about marketing budgets in video games.\" \"Did you say slapfight?\"  \\\n",
       "0                                                  0                                                    \n",
       "1                                                  0                                                    \n",
       "2                                                  0                                                    \n",
       "3                                                  0                                                    \n",
       "4                                                  0                                                    \n",
       "\n",
       "   title_\"Art\" by Salvador Larroca..  \\\n",
       "0                                  0   \n",
       "1                                  0   \n",
       "2                                  0   \n",
       "3                                  0   \n",
       "4                                  0   \n",
       "\n",
       "   title_\"Attorney Denies Robert De Niro Was Client of Prostitution Ring With Underage Girls; Police Interrogated Star for Nine Hours – True PunditTrue Pundit\" A *Nine* hour interview and his very high priced Lawyers would've been pushing for it to be brief to prevent inadvertent selfincriminating. Right?  \\\n",
       "0                                                  0                                                                                                                                                                                                                                                                 \n",
       "1                                                  0                                                                                                                                                                                                                                                                 \n",
       "2                                                  0                                                                                                                                                                                                                                                                 \n",
       "3                                                  0                                                                                                                                                                                                                                                                 \n",
       "4                                                  0                                                                                                                                                                                                                                                                 \n",
       "\n",
       "   title_\"Automata\" DUST Trailer - Episode 1 premieres on June 12th  \\\n",
       "0                                                  0                  \n",
       "1                                                  0                  \n",
       "2                                                  0                  \n",
       "3                                                  0                  \n",
       "4                                                  0                  \n",
       "\n",
       "   title_\"Balancing Act\", Digital, 720x720, Collab with Broken Isnt Bad  \\\n",
       "0                                                  0                      \n",
       "1                                                  0                      \n",
       "2                                                  0                      \n",
       "3                                                  0                      \n",
       "4                                                  0                      \n",
       "\n",
       "   title_\"Bandit\" in cinemas soon  \\\n",
       "0                               0   \n",
       "1                               0   \n",
       "2                               0   \n",
       "3                               0   \n",
       "4                               0   \n",
       "\n",
       "   title_\"Canada burned down the White House during the war of 1812\" - Trump  \\\n",
       "0                                                  0                           \n",
       "1                                                  0                           \n",
       "2                                                  0                           \n",
       "3                                                  0                           \n",
       "4                                                  0                           \n",
       "\n",
       "   title_\"Coffee, tea, or... me?\"         ...          subreddit_xxfitness  \\\n",
       "0                               0         ...                            0   \n",
       "1                               0         ...                            0   \n",
       "2                               0         ...                            0   \n",
       "3                               0         ...                            0   \n",
       "4                               0         ...                            0   \n",
       "\n",
       "   subreddit_yakuzagames  subreddit_yesyesyesno  subreddit_yesyesyesyesno  \\\n",
       "0                      0                      0                         0   \n",
       "1                      0                      0                         0   \n",
       "2                      0                      0                         0   \n",
       "3                      0                      0                         0   \n",
       "4                      0                      0                         0   \n",
       "\n",
       "   subreddit_youdontsurf  subreddit_youseeingthisshit  subreddit_youtube  \\\n",
       "0                      0                            0                  0   \n",
       "1                      0                            0                  0   \n",
       "2                      0                            0                  0   \n",
       "3                      0                            0                  0   \n",
       "4                      0                            0                  0   \n",
       "\n",
       "   subreddit_youtubehaiku  subreddit_zelda  subreddit_zerocarb  \n",
       "0                       0                0                   0  \n",
       "1                       0                0                   0  \n",
       "2                       0                0                   0  \n",
       "3                       0                0                   0  \n",
       "4                       0                0                   0  \n",
       "\n",
       "[5 rows x 6671 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Validation \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6519267214150347\n",
      "0.9336403033586133\n"
     ]
    }
   ],
   "source": [
    "# RFM\n",
    "\n",
    "RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "print(rf.score(X_test, y_test))\n",
    "print(rf.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6592632719393283\n",
      "{'min_samples_split': 3, 'n_estimators': 150}\n",
      "0.995124593716143\n"
     ]
    }
   ],
   "source": [
    "# Model seems to be overfit, using gridsearch to reduce overfitting.\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_params = {'min_samples_split' : range(2,5),\n",
    "            'n_estimators': [50, 100, 150]}\n",
    "\n",
    "GridSearchCV(rf, param_grid = rf_params) \n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "print(gs.best_params_)\n",
    "print(gs.score(X_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These features are not helping the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "9367beff-72ba-4768-a0ba-a50b335de61d"
   },
   "source": [
    "#### Use cross-validation in scikit-learn to evaluate the model above. \n",
    "- Evaluate the accuracy of the model, as well as any other metrics you feel are appropriate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "focus": false,
    "id": "269b9e7c-60b5-4a06-8255-881d7395bc1b"
   },
   "outputs": [],
   "source": [
    "## Gridsearch above, now doing cross validation \n",
    "\n",
    "cross_validation = cross_val_score(gs, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.65764547 0.67388363 0.67208672 0.67615176 0.64498645]\n"
     ]
    }
   ],
   "source": [
    "print(cross_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Receiving accuracy scores of about 50-60%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Repeat the model-building process with a non-tree-based method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>time fetched</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Removed the top of my desk for cleaning. Cat d...</td>\n",
       "      <td>aww</td>\n",
       "      <td>486</td>\n",
       "      <td>2018-06-11 19:27:23</td>\n",
       "      <td>8qc84c</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tina Fey Says Liz Lemon And Leslie Knope Shoul...</td>\n",
       "      <td>television</td>\n",
       "      <td>990</td>\n",
       "      <td>2018-06-11 18:31:18</td>\n",
       "      <td>8qbqmn</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Just keep it steady</td>\n",
       "      <td>combinedgifs</td>\n",
       "      <td>235</td>\n",
       "      <td>2018-06-11 17:37:08</td>\n",
       "      <td>8qbbb3</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cat saves his buddy from falling off a ledge</td>\n",
       "      <td>AnimalsBeingBros</td>\n",
       "      <td>211</td>\n",
       "      <td>2018-06-11 17:10:42</td>\n",
       "      <td>8qb37o</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Time-lapse of rain storm</td>\n",
       "      <td>woahdude</td>\n",
       "      <td>175</td>\n",
       "      <td>2018-06-11 17:02:18</td>\n",
       "      <td>8qb0qq</td>\n",
       "      <td>2018-06-11 22:15:51</td>\n",
       "      <td>HIGH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title         subreddit  \\\n",
       "0  Removed the top of my desk for cleaning. Cat d...               aww   \n",
       "1  Tina Fey Says Liz Lemon And Leslie Knope Shoul...        television   \n",
       "2                                Just keep it steady      combinedgifs   \n",
       "3       Cat saves his buddy from falling off a ledge  AnimalsBeingBros   \n",
       "4                           Time-lapse of rain storm          woahdude   \n",
       "\n",
       "   num_comments          created_utc      id         time fetched Class  \n",
       "0           486  2018-06-11 19:27:23  8qc84c  2018-06-11 22:15:51  HIGH  \n",
       "1           990  2018-06-11 18:31:18  8qbqmn  2018-06-11 22:15:51  HIGH  \n",
       "2           235  2018-06-11 17:37:08  8qbbb3  2018-06-11 22:15:51  HIGH  \n",
       "3           211  2018-06-11 17:10:42  8qb37o  2018-06-11 22:15:51  HIGH  \n",
       "4           175  2018-06-11 17:02:18  8qb0qq  2018-06-11 22:15:51  HIGH  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment_predictor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Going to do a couple different models with different features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit_13or30</th>\n",
       "      <th>subreddit_1500isplenty</th>\n",
       "      <th>subreddit_2healthbars</th>\n",
       "      <th>subreddit_2mad4madlads</th>\n",
       "      <th>subreddit_2meirl42meirl4meirl</th>\n",
       "      <th>subreddit_2meirl4meirl</th>\n",
       "      <th>subreddit_3DS</th>\n",
       "      <th>subreddit_3Dprinting</th>\n",
       "      <th>subreddit_3amjokes</th>\n",
       "      <th>...</th>\n",
       "      <th>subreddit_xxfitness</th>\n",
       "      <th>subreddit_yakuzagames</th>\n",
       "      <th>subreddit_yesyesyesno</th>\n",
       "      <th>subreddit_yesyesyesyesno</th>\n",
       "      <th>subreddit_youdontsurf</th>\n",
       "      <th>subreddit_youseeingthisshit</th>\n",
       "      <th>subreddit_youtube</th>\n",
       "      <th>subreddit_youtubehaiku</th>\n",
       "      <th>subreddit_zelda</th>\n",
       "      <th>subreddit_zerocarb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>486</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>990</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>211</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1933 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_comments  subreddit_13or30  subreddit_1500isplenty  \\\n",
       "0           486                 0                       0   \n",
       "1           990                 0                       0   \n",
       "2           235                 0                       0   \n",
       "3           211                 0                       0   \n",
       "4           175                 0                       0   \n",
       "\n",
       "   subreddit_2healthbars  subreddit_2mad4madlads  \\\n",
       "0                      0                       0   \n",
       "1                      0                       0   \n",
       "2                      0                       0   \n",
       "3                      0                       0   \n",
       "4                      0                       0   \n",
       "\n",
       "   subreddit_2meirl42meirl4meirl  subreddit_2meirl4meirl  subreddit_3DS  \\\n",
       "0                              0                       0              0   \n",
       "1                              0                       0              0   \n",
       "2                              0                       0              0   \n",
       "3                              0                       0              0   \n",
       "4                              0                       0              0   \n",
       "\n",
       "   subreddit_3Dprinting  subreddit_3amjokes         ...          \\\n",
       "0                     0                   0         ...           \n",
       "1                     0                   0         ...           \n",
       "2                     0                   0         ...           \n",
       "3                     0                   0         ...           \n",
       "4                     0                   0         ...           \n",
       "\n",
       "   subreddit_xxfitness  subreddit_yakuzagames  subreddit_yesyesyesno  \\\n",
       "0                    0                      0                      0   \n",
       "1                    0                      0                      0   \n",
       "2                    0                      0                      0   \n",
       "3                    0                      0                      0   \n",
       "4                    0                      0                      0   \n",
       "\n",
       "   subreddit_yesyesyesyesno  subreddit_youdontsurf  \\\n",
       "0                         0                      0   \n",
       "1                         0                      0   \n",
       "2                         0                      0   \n",
       "3                         0                      0   \n",
       "4                         0                      0   \n",
       "\n",
       "   subreddit_youseeingthisshit  subreddit_youtube  subreddit_youtubehaiku  \\\n",
       "0                            0                  0                       0   \n",
       "1                            0                  0                       0   \n",
       "2                            0                  0                       0   \n",
       "3                            0                  0                       0   \n",
       "4                            0                  0                       0   \n",
       "\n",
       "   subreddit_zelda  subreddit_zerocarb  \n",
       "0                0                   0  \n",
       "1                0                   0  \n",
       "2                0                   0  \n",
       "3                0                   0  \n",
       "4                0                   0  \n",
       "\n",
       "[5 rows x 1933 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Features num_comments and subredddit \n",
    "X = comment_predictor[['num_comments', 'subreddit']].copy(deep=True) #I'm still not sure what the deep=True is doing, but I'm sticking with it to not mess anything up\n",
    "y = comment_predictor['Class'].apply(lambda x: 1 if x == 'HIGH' else 0)\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am running into some errors here having to deal with \n",
    "# value errors. There are a mismatch of features \n",
    "# between my training and test data. \n",
    "\n",
    "#Using helpful code to try and solve it \n",
    "\n",
    "# Look at all 3 features: title, subreddit, and age\n",
    "X = comment_predictor[['num_comments', 'subreddit']].copy(deep = True)\n",
    "y = comment_predictor['Class'].apply(lambda x: 1 if x == 'HIGH' else 0)\n",
    "\n",
    "X = pd.get_dummies(X, columns = ['subreddit'], drop_first = True)\n",
    "\n",
    "# Train / Test split \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n",
    "\n",
    "# Define function to make sure features are the same in both the train and test \n",
    "def feature_check(train, test):\n",
    "    missing_cols = set(train.columns) - set(test.columns)\n",
    "    for c in missing_cols:\n",
    "        test[c] = 0\n",
    "    test = test[train.columns]\n",
    "    return test\n",
    "\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now rebuilding the model process using Multinomial Naive Bayes and Logistic Regression\n",
    "\n",
    "# Train/Test Split\n",
    "\n",
    "X_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression 75% accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8894504106127605"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 88% accuracy with Multinomial NB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_comments</th>\n",
       "      <td>1.817401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_2healthbars</th>\n",
       "      <td>1.382472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_exjw</th>\n",
       "      <td>1.372397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_RealmRoyale</th>\n",
       "      <td>1.359520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_Fishing</th>\n",
       "      <td>1.355772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_reddevils</th>\n",
       "      <td>1.327084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_CasualUK</th>\n",
       "      <td>1.306744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_firstworldanarchists</th>\n",
       "      <td>1.269877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_Floof</th>\n",
       "      <td>1.264200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_marvelstudios</th>\n",
       "      <td>1.241404</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    coef\n",
       "num_comments                    1.817401\n",
       "subreddit_2healthbars           1.382472\n",
       "subreddit_exjw                  1.372397\n",
       "subreddit_RealmRoyale           1.359520\n",
       "subreddit_Fishing               1.355772\n",
       "subreddit_reddevils             1.327084\n",
       "subreddit_CasualUK              1.306744\n",
       "subreddit_firstworldanarchists  1.269877\n",
       "subreddit_Floof                 1.264200\n",
       "subreddit_marvelstudios         1.241404"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefs = pd.DataFrame(logreg.coef_[0], index = X.columns, columns = ['coef'])\n",
    "coefs['coef'] = np.exp(coefs['coef'])\n",
    "coefs.sort_values(by='coef', ascending = False, inplace=True)\n",
    "coefs.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Use Count Vectorizer from scikit-learn to create features from the thread titles. \n",
    "- Examine using count or binary features in the model\n",
    "- Re-evaluate your models using these. Does this improve the model performance? \n",
    "- What text features are the most valuable? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>num_comments</th>\n",
       "      <td>6.155840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_2healthbars</th>\n",
       "      <td>3.984740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_exjw</th>\n",
       "      <td>3.944795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_RealmRoyale</th>\n",
       "      <td>3.894325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_Fishing</th>\n",
       "      <td>3.879754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_reddevils</th>\n",
       "      <td>3.770033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_CasualUK</th>\n",
       "      <td>3.694124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_firstworldanarchists</th>\n",
       "      <td>3.560414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_Floof</th>\n",
       "      <td>3.540259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subreddit_marvelstudios</th>\n",
       "      <td>3.460468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    coef\n",
       "num_comments                    6.155840\n",
       "subreddit_2healthbars           3.984740\n",
       "subreddit_exjw                  3.944795\n",
       "subreddit_RealmRoyale           3.894325\n",
       "subreddit_Fishing               3.879754\n",
       "subreddit_reddevils             3.770033\n",
       "subreddit_CasualUK              3.694124\n",
       "subreddit_firstworldanarchists  3.560414\n",
       "subreddit_Floof                 3.540259\n",
       "subreddit_marvelstudios         3.460468"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking highest coefficients!\n",
    "\n",
    "coefs = pd.DataFrame(logreg.coef_[0], index = X.columns, columns = ['coef'])\n",
    "coefs['coef'] = np.exp(coefs['coef'])\n",
    "coefs.sort_values(by='coef', ascending = False, inplace=True)\n",
    "coefs.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN Model\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With the number of comments and subreddit features, both KNN and Logistic Regression performed the best."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Count Vectorizer from scikit-learn to create features from the thread titles.\n",
    "### Examine using count or binary features in the model\n",
    "### Re-evaluate your models using these. Does this improve the model performance?\n",
    "### What text features are the most valuable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = comment_predictor['subreddit']\n",
    "y = comment_predictor['Class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec = CountVectorizer(stop_words = 'english', binary=False)\n",
    "cvec.fit(X_train)\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.599696739954511"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(random_state=42)\n",
    "rf.fit(X_train_cvec, y_train)\n",
    "rf.score(X_test_cvec, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest did better! by 5%!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6724791508718726"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_cvec, y_train)\n",
    "logreg.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression went from 75% to 42%, way worse. Sad! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5625473843821076"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train_cvec, y_train)\n",
    "knn.score(X_test_cvec, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN also went from 75% to 42%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I had a bit of trouble using cvec to run with other features like number of comments, which is something I wanted to do instead. For some reason I think the value was too low. The error was something along lines of minimum of 2, but I had something with 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Executive Summary\n",
    "---\n",
    "Put your executive summary in a Markdown cell below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "3be94357-e551-4094-b784-2df039216d33"
   },
   "source": [
    "### BONUS\n",
    "Refer to the README for the bonus parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "4239e458-28bd-4675-8db3-c1d9c02b9854"
   },
   "source": [
    "#### I sort of stumbeled my way through this one before grasping all the concepts, even though I was learning how to use them while doing the project.. My models didn't perform exceptionally well, highest being logistic regression and knn at 75%. I did manage to learn that subreddits with their own followers really get the most traffic. Among those subreddits, it was gaming stuff (which means people like me), and funny posts. My 3rd largest subreddit was white people twitter, which I'm sure is just as hilarious as it sounds. If I were to give advice to someone to make reddit posts I would let them know that a lot of it can come down to human activity on subreddits, which can sometimes be unpredictable. Finding a specific subreddit to tie their post into would be really helpful since those seem to have people that follow them already, and are a little less random - if they really wanted some exposure, somehow tying it to video games or something funny, may be a good route to take. Personally, I learned quite a bit while putting the models to use, even though maybe not all of them are being used correctly, the syntax is starting to sync in. My workflow is still a bit messy because I find myself sometimes struggling what I am tryin gto achieve while I am doing it, but I think with enough practice it will get there. The most interesting thing for me was probably seeing how drastically different models and features perform given the same dataset. I also think changing the way we did our High/Low comment class could maybe use some tweaking so it wasn't so black and white for how our posts got sorted. It seems a little too skewed to be helpful for me, but I could be wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
